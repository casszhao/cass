---
layout: default
---

## About Me

<img class="profile-picture" src="avatar.jpg">

I am Cass Zhixue Zhao, a lecturer (Assistant Professor) in [Natural Language Processing](https://www.sheffield.ac.uk/dcs/research/groups/natural-language-processing) at the Computer Science Department of the University of Sheffield. My long-term research goal is to enable trustworthy, responsible, and efficient NLP models. These days, I am interested in anything related to **interpretability** and **large language models** (LLMs). My recent research projects focus on **model compression**, **model editing**, and **text-to-image models**. Previously, I served as co-Principal Investigator on the [ExU](https://exuproject.sites.sheffield.ac.uk/) project, developing multilingual AI tools to support journalists and fact-checkers in identifying disinformation narratives.

Previously, I worked as a Postdoc researcher on explainable AI and responsible AI. The overarching aim is to demystify predictions made by black-box LLMs, making them easier to understand and trustworthy. The work also addresses model hallucination to ensure the reliability of LLMs, alongside exploring model compression techniques that mitigate compute demands and thus foster inclusivity within NLP research. Back in 2020, I worked as a research assistant within the same department, working on NIHR-funded NLP projects for systematic reviews of public health research. My Ph.D. research, which was funded by the University of Sheffield, looked at transfer learning and mitigating model bias for hate speech detection.


<font color=White>Test</font>
<font color=White>Test</font>

I am looking for highly motivated PhD students. <font color=blue>One funded PhD positions</font> for 3.5 years will be available in late 2026, UKRI rate. Welcome to contact me with your CV ready. CSC or Self-funding with your own topic is welcome too.

<font color=White>Test</font>
<font color=White>Test</font>

## Selected Publications

[ICML2025](https://openreview.net/pdf?id=uqpML2nbIz) Rulebreakers Challenge: Revealing a Blind Spot in Large Language Models’ Reasoning with Formal Logic.

Jason Chan, Robert Gaizauskas, **<span style="color:grey">Zhixue Zhao</span>**


[ICML2025](https://openreview.net/pdf?id=QLKBm1PaCU) Position: Editing Large Language Models Poses Serious Safety Risks. 

Paul Youssef, **<span style="color:grey">Zhixue Zhao</span>**, Daniel Braun, Jörg Schlötterer, Christin Seifert


[ICLR2025](https://openreview.net/pdf?id=ugyqNEOjoU) ScImage: How good are multimodal large language models at scientific text-to-image generation? 

Leixin Zhang, Yinjie Cheng, Weihe Zhai, Steffen Eger, Jonas Belouadi, Fahimeh Moafian, **<span style="color:grey">Zhixue Zhao</span>**. 


[EMNLP2025 Main](https://arxiv.org/pdf/2412.03400?) Minimal, Local, and Robust: Embedding-Only Edits for Implicit Bias in T2I Models

Feng He, Chao Zhang, **<span style="color:grey">Zhixue Zhao</span>**


[EMNLP2025 Main](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=bwiMxxsAAAAJ&sortby=pubdate&citation_for_view=bwiMxxsAAAAJ:hqOjcs7Dif8C) Label Set Optimization via Activation Distribution Kurtosis for Zero-Shot Classification with Generative Models

Yue Li, **<span style="color:grey">Zhixue Zhao</span>**, Carolina Scarton


[EMNLP2025 Main] It's All About In-Context Learning! Teaching Extremely Low-Resource Languages to LLMs

Yue Li, **<span style="color:grey">Zhixue Zhao</span>**, Carolina Scarton

	
[EMNLP2025 Findings] Revisiting Pruning vs Quantization for Small Language Models

Zihan Zhou, Simon Kurz, **<span style="color:grey">Zhixue Zhao</span>**


[EMNLP2025 Main] Analysing Chain of Thought Dynamics: Active Guidance or Unfaithful Post-hoc Rationalisation?

Samuel Lewis-Lim, Xingwei Tan, **<span style="color:grey">Zhixue Zhao</span>**, Nikolaos Aletras


[ACL2025 Main](https://aclanthology.org/2025.acl-long.1063/). Knowledge Image Matters: Improving Knowledge-Based Visual Reasoning with Multi-Image Large Language Models

Guanghui Ye, Huan Zhao, **<span style="color:grey">Zhixue Zhao</span>**, Xupeng Zha, Yang Liu, Zhihua Jiang


[ACL2025 Findings](https://aclanthology.org/2025.findings-acl.96/) Explainable Hallucination through Natural Language Inference Mapping

Wei-Fan Chen, **<span style="color:grey">Zhixue Zhao</span>**, Akbar Karimi, Lucie Flek


[NAACL2025 Main](https://aclanthology.org/2025.naacl-long.630/) How to Make LLMs Forget: On Reversing In-Context Knowledge Edits

Paul Youssef, **<span style="color:grey">Zhixue Zhao</span>**, Jörg Schlötterer, Christin Seifert. 


[NAACL2025 Main Oral](https://aclanthology.org/2025.naacl-long.492/) Has this Fact been Edited? Detecting Knowledge Edits in Language Models?

Paul Youssef, **<span style="color:grey">Zhixue Zhao</span>**, Jörg Schlötterer, Christin Seifert. 


[TACL2024 Vol. 12](https://transacl.org/index.php/tacl/article/view/6271) Investigating Hallucinations in Pruned Large Language Models for Abstractive Summarization.  

George Chrysostomou, **<span style="color:grey">Zhixue Zhao</span>**, Miles Williams, and Nikolaos Aletras. 


[NAACL 2024 Main](https://arxiv.org/pdf/2403.12809) (oral presentation) Comparing Explanation Faithfulness between Multilingual and Monolingual Fine-tuned Language Models. 

**<span style="color:grey">Zhixue Zhao</span>** and Nikolaos Aletras.

[ACL 2023 Main](https://aclanthology.org/2023.acl-long.261/)
[[Oral Presentation](https://us06web.zoom.us/rec/play/TisLvdRrfqNRYts4y0A6wJeoV2H6kL2eRywX7Jl_wGUxBVO_n_HoIfVi1lhO0OK1sUw-gDjFpHuuDz6o.-zDGXXlaq7nOwrW7?canPlayFromShare=true&from=share_recording_detail&continueMode=true&componentName=rec-play&originRequestUrl=https%3A%2F%2Fus06web.zoom.us%2Frec%2Fshare%2Fc0BepePE3QACrdQQpFnEISDmrUSvV5T7XwJcW1TN0jkGEvVMutm55KeLx9eKWXH4.R0SYaV552qVO0sfV) (the 1st talk was ours)] Incorporating Attribution Importance for Improving Faithfulness Metrics.

**<span style="color:grey">Zhixue Zhao</span>** and Nikolaos Aletras.


[EMNLP 2022 Findings](https://aclanthology.org/2022.findings-emnlp.298/) On the Impact of Temporal Concept Drift on Model Explanations. 

**<span style="color:grey">Zhixue Zhao</span>**, George Chrysostomou, Kalina Bontcheva, and Nikolaos Aletras.



(More papers in [publications](https://casszhao.github.io/cass/publications).)


<font color=White>Test</font>
<font color=White>Test</font>


<font color=White>Test</font>
## Project
- Co-PI of [ExU](https://exuproject.sites.sheffield.ac.uk/)
