---
layout: default
---

## About Me

<img class="profile-picture" src="avatar.jpg">

I am Cass Zhixue Zhao, a lecturer (Assistant Professor) in [Natural Language Processing](https://www.sheffield.ac.uk/dcs/research/groups/natural-language-processing) at the Computer Science Department of the University of Sheffield. My long-term research goal is to enable trustworthy, responsible, and efficient NLP models. These days, I am interested in anything related to **interpretability** and **large language models** (LLMs). My recent research projects focus on **model compression**, **model editing**, and **text-to-image models**. Previously, I served as co-Principal Investigator on the [ExU](https://exuproject.sites.sheffield.ac.uk/) project, developing multilingual AI tools to support journalists and fact-checkers in identifying disinformation narratives.

Previously, I worked as a Postdoc researcher on explainable AI and responsible AI. The overarching aim is to demystify predictions made by black-box LLMs, making them easier to understand and trustworthy. The work also addresses model hallucination to ensure the reliability of LLMs, alongside exploring model compression techniques that mitigate compute demands and thus foster inclusivity within NLP research. Back in 2020, I worked as a research assistant within the same department, working on NIHR-funded NLP projects for systematic reviews of public health research. My Ph.D. research, funded by the University of Sheffield, examined transfer learning and mitigating model bias in hate speech detection.


<font color=White>Test</font>
<font color=White>Test</font>

ðŸš€ One UK home standard studentship is available in 2027 [@SheffieldNLP](https://x.com/SheffieldNLP). Join us to explore cutting-edge topics in AI safety and Generative AI integrity ðŸ§ âœ¨ Get in touch if youâ€™d like to chat about the PhD, our research, or life in Sheffield! 

ðŸ“© If youâ€™re considering self-funding or already have external funding, please feel free to contact me with your CV. Visiting students are also very welcome!




<font color=White>Test</font>
<font color=White>Test</font>

## Selected Publications in 2025/26



[AAAI26 Oral](https://arxiv.org/pdf/2505.12189) Mitigating Content Effects on Reasoning in Language Models through Fine-Grained Activation Steering

Marco Valentino, Geonhee Kim, Dhairya Dalal, **<span style="color:grey">Zhixue Zhao</span>**, Andre Freitas


[AAAI2026 Poster](https://aaai.org/conference/aaai/aaai-26/main-technical-track-call/) Making Visual Dialogue More Engaging: A New Task, Method, and Metric

Guanghui Ye, Huan Zhao, Yingxue Gao, **<span style="color:grey">Zhixue Zhao</span>**, Kehan Wang, Xupeng Zha, Zhihua Jiang


[ICWSM26](https://arxiv.org/abs/2505.18916) SCRum-9: Multilingual Stance Classification over Rumours on Social Media

Yue Li, Jake Vasilakes, **<span style="color:grey">Zhixue Zhao</span>**, Carolina Scarton


[EACL2026 Main](https://arxiv.org/pdf/2512.12503) KidsArtBench: Multi-Dimensional Childrenâ€™s Art Evaluation with Attribute-Aware MLLMs

Mingrui Ye, Chanjin Zheng, Zengyi Yu, Chenyu Xiang, **<span style="color:grey">Zhixue Zhao</span>**, Zheng Yuan, Helen Yannakoudakis 


[EACL2026 Findings](https://arxiv.org/pdf/2506.06113?) Seeing All Sides: Multi-Perspective In-Context Learning for Subjective NLP

Benedetta Muscato, Yue Li, Gizem Gezici, **<span style="color:grey">Zhixue Zhao</span>**, Fosca Giannotti 


[ICML2025](https://openreview.net/pdf?id=uqpML2nbIz) Rulebreakers Challenge: Revealing a Blind Spot in Large Language Modelsâ€™ Reasoning with Formal Logic.

Jason Chan, Robert Gaizauskas, **<span style="color:grey">Zhixue Zhao</span>**


[ICML2025](https://openreview.net/pdf?id=QLKBm1PaCU) Position: Editing Large Language Models Poses Serious Safety Risks. 

Paul Youssef, **<span style="color:grey">Zhixue Zhao</span>**, Daniel Braun, JÃ¶rg SchlÃ¶tterer, Christin Seifert


[ICLR2025](https://openreview.net/pdf?id=ugyqNEOjoU) ScImage: How good are multimodal large language models at scientific text-to-image generation? 

Leixin Zhang, Yinjie Cheng, Weihe Zhai, Steffen Eger, Jonas Belouadi, Fahimeh Moafian, **<span style="color:grey">Zhixue Zhao</span>**


[TACL2025](https://arxiv.org/pdf/2408.14398) Investigating Language-Specific Calibration for Pruning Multilingual Large Language Models

Simon Kurz, Jian-Jia Chen, Lucie Flek, **<span style="color:grey">Zhixue Zhao</span>**


[EMNLP2025 Main](https://arxiv.org/pdf/2412.03400?) Minimal, Local, and Robust: Embedding-Only Edits for Implicit Bias in T2I Models

Feng He, Chao Zhang, **<span style="color:grey">Zhixue Zhao</span>**


[EMNLP2025 Main Oral Top15%](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=bwiMxxsAAAAJ&sortby=pubdate&citation_for_view=bwiMxxsAAAAJ:hqOjcs7Dif8C) Label Set Optimization via Activation Distribution Kurtosis for Zero-Shot Classification with Generative Models

Yue Li, **<span style="color:grey">Zhixue Zhao</span>**, Carolina Scarton


[EMNLP2025 Main](https://arxiv.org/pdf/2508.19089) It's All About In-Context Learning! Teaching Extremely Low-Resource Languages to LLMs

Yue Li, **<span style="color:grey">Zhixue Zhao</span>**, Carolina Scarton

	
[EMNLP2025 Findings](QP.pdf) Revisiting Pruning vs Quantization for Small Language Models

Zihan Zhou, Simon Kurz, **<span style="color:grey">Zhixue Zhao</span>**


[EMNLP2025 Main](https://arxiv.org/abs/2508.19827) Analysing Chain of Thought Dynamics: Active Guidance or Unfaithful Post-hoc Rationalisation?

Samuel Lewis-Lim, Xingwei Tan, **<span style="color:grey">Zhixue Zhao</span>**, Nikolaos Aletras


[ACL2025 Main](https://aclanthology.org/2025.acl-long.1063/). Knowledge Image Matters: Improving Knowledge-Based Visual Reasoning with Multi-Image Large Language Models

Guanghui Ye, Huan Zhao, **<span style="color:grey">Zhixue Zhao</span>**, Xupeng Zha, Yang Liu, Zhihua Jiang


[ACL2025 Findings](https://aclanthology.org/2025.findings-acl.96/) Explainable Hallucination through Natural Language Inference Mapping

Wei-Fan Chen, **<span style="color:grey">Zhixue Zhao</span>**, Akbar Karimi, Lucie Flek


[Knowledge-Based Systems 2025](https://www.sciencedirect.com/science/article/pii/S0950705125016739) AI-generated content in cross-domain applications: Research trends, challenges and propositions

Jianxin Li, Liang Qu, Taotao Cai, **<span style="color:grey">Zhixue Zhao</span>**, Nur Al Hasan Haldar, Aneesh Krishna, Xiangjie Kong, Flavio Romero Macau, Tanmoy Chakraborty, Aniket Deroy, Binshan Lin, Karen Blackmore, Nasimul Noman, Jingxian Cheng, Ningning Cui, Jianliang Xu


[IEEE Transactions on Computational Social Systems](https://ieeexplore.ieee.org/document/11080351) CCDE: A Compact and Competitive Dialogue Evaluation Framework via Knowledge Distillation of Large Language Models

Guanghui Ye; Huan Zhao; Bo Li; Haijiao Chen; **<span style="color:grey">Zhixue Zhao</span>**; Zhihua Jiang

[NAACL2025 Main](https://aclanthology.org/2025.naacl-long.630/) How to Make LLMs Forget: On Reversing In-Context Knowledge Edits

Paul Youssef, **<span style="color:grey">Zhixue Zhao</span>**, JÃ¶rg SchlÃ¶tterer, Christin Seifert. 


[NAACL2025 Main Oral](https://aclanthology.org/2025.naacl-long.492/) Has this Fact been Edited? Detecting Knowledge Edits in Language Models?

Paul Youssef, **<span style="color:grey">Zhixue Zhao</span>**, JÃ¶rg SchlÃ¶tterer, Christin Seifert. 




(More papers in [publications](https://casszhao.github.io/cass/publications).)


<font color=White>Test</font>




## Project
- Co-PI of [ExU](https://exuproject.sites.sheffield.ac.uk/)
