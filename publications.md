---
layout: default
is_contact: true
---



## Publications

[TACL2025 under review](https://arxiv.org/pdf/2408.14398) Investigating Language-Specific Calibration for Pruning Multilingual Large Language Models
Simon Kurz, Jian-Jia Chen, Lucie Flek, **<span style="color:grey">Zhixue Zhao</span>**

[Preprint](https://arxiv.org/pdf/2412.03400) Implicit Priors Editing in Stable Diffusion via Targeted Token
Adjustment 
Feng He, Chao Zhang, **<span style="color:grey">Zhixue Zhao</span>**

[ICML2025](https://icml.cc/virtual/2025/poster/40144) Rulebreakers Challenge: Revealing a Blind Spot in Large Language Models’ Reasoning with Formal Logic.

Jason Chan, Robert Gaizauskas, **<span style="color:grey">Zhixue Zhao</span>**


[ICML2025](https://arxiv.org/pdf/2502.02958) Position: Editing Large Language Models Poses Serious Safety Risks. 

Paul Youssef, **<span style="color:grey">Zhixue Zhao</span>**, Daniel Braun, Jörg Schlötterer, Christin Seifert


[ICLR2025](https://iclr.cc/virtual/2025/poster/27964) ScImage: How good are multimodal large language models at scientific text-to-image generation? 

Leixin Zhang, Yinjie Cheng, Weihe Zhai, Steffen Eger, Jonas Belouadi, Fahimeh Moafian, **<span style="color:grey">Zhixue Zhao</span>**. 


[ACL2025 Main](https://2025.aclweb.org/) Preprint coming soon. Knowledge Image Matters: Improving Knowledge-Based Visual Reasoning with Multi-Image Large Language Models

Guanghui Ye, Huan Zhao, **<span style="color:grey">Zhixue Zhao</span>**, Xupeng Zha, Yang Liu, Zhihua Jiang


[ACL2025 Findings](https://2025.aclweb.org/) Preprint coming soon. Explainable Hallucination through Natural Language Inference Mapping

Wei-Fan Chen, **<span style="color:grey">Zhixue Zhao</span>**, Akbar Karimi, Lucie Flek


[NAACL2025 Main](https://arxiv.org/pdf/2410.12586) Can We Reverse In-Context Knowledge Edits?

Paul Youssef, **<span style="color:grey">Zhixue Zhao</span>**, Jörg Schlötterer, Christin Seifert. 


[NAACL2025 Main Oral](https://arxiv.org/pdf/2405.02765) Has this Fact been Edited? Detecting Knowledge Edits in Language Models?

Paul Youssef, **<span style="color:grey">Zhixue Zhao</span>**, Jörg Schlötterer, Christin Seifert. 

[ECIR2025](https://link.springer.com/chapter/10.1007/978-3-031-88714-7_30) Do LLMs Provide Consistent Answers to Health-Related Questions Across Languages? 
Ipek Baris Schlicht, **<span style="color:grey">Zhixue Zhao</span>**, Burcu Sayin, Lucie Flek, Paolo Rosso 

[TACL2024 Vol. 12](https://transacl.org/index.php/tacl/article/view/6271) Investigating Hallucinations in Pruned Large Language Models for Abstractive Summarization.  

George Chrysostomou, **<span style="color:grey">Zhixue Zhao</span>**, Miles Williams, and Nikolaos Aletras. 


[NAACL 2024 Main](https://arxiv.org/pdf/2403.12809) (oral presentation) Comparing Explanation Faithfulness between Multilingual and Monolingual Fine-tuned Language Models. 

**<span style="color:grey">Zhixue Zhao</span>** and Nikolaos Aletras.

[ACL 2023 Main](https://aclanthology.org/2023.acl-long.261/)
[[Oral Presentation](https://us06web.zoom.us/rec/play/TisLvdRrfqNRYts4y0A6wJeoV2H6kL2eRywX7Jl_wGUxBVO_n_HoIfVi1lhO0OK1sUw-gDjFpHuuDz6o.-zDGXXlaq7nOwrW7?canPlayFromShare=true&from=share_recording_detail&continueMode=true&componentName=rec-play&originRequestUrl=https%3A%2F%2Fus06web.zoom.us%2Frec%2Fshare%2Fc0BepePE3QACrdQQpFnEISDmrUSvV5T7XwJcW1TN0jkGEvVMutm55KeLx9eKWXH4.R0SYaV552qVO0sfV) (the 1st talk was ours)] Incorporating Attribution Importance for Improving Faithfulness Metrics.

**<span style="color:grey">Zhixue Zhao</span>** and Nikolaos Aletras.


[EMNLP 2022 Findings](https://aclanthology.org/2022.findings-emnlp.298/) On the Impact of Temporal Concept Drift on Model Explanations. 

**<span style="color:grey">Zhixue Zhao</span>**, George Chrysostomou, Kalina Bontcheva, and Nikolaos Aletras.


[JAMIA Vol.7 4(2024)](https://doi.org/10.1093/jamiaopen/ooae139) The FAIR database: facilitating access to public health research literature. 
**<span style="color:grey">Zhixue Zhao</span>**, James Thomas, Gregory Kell, Claire Stansfield, Mark Clowes, Sergio Graziosi, Jeff Brunton, Iain James Marshall, Mark Stevenson. 


[ACL 2023 Main](https://aclanthology.org/2023.acl-long.261/)
[[Oral Presentation](https://us06web.zoom.us/rec/play/TisLvdRrfqNRYts4y0A6wJeoV2H6kL2eRywX7Jl_wGUxBVO_n_HoIfVi1lhO0OK1sUw-gDjFpHuuDz6o.-zDGXXlaq7nOwrW7?canPlayFromShare=true&from=share_recording_detail&continueMode=true&componentName=rec-play&originRequestUrl=https%3A%2F%2Fus06web.zoom.us%2Frec%2Fshare%2Fc0BepePE3QACrdQQpFnEISDmrUSvV5T7XwJcW1TN0jkGEvVMutm55KeLx9eKWXH4.R0SYaV552qVO0sfV)] (the 1st talk was ours) Incorporating Attribution Importance for Improving Faithfulness Metrics. The 61st Annual Meeting of the Association for Computational Linguistics.
**<span style="color:grey">Zhixue Zhao</span>** and Nikolaos Aletras. 


[[ReLM@AAAI24](https://arxiv.org/pdf/2402.00794)] Use ReAGent via [Inseq](https://inseq.org/en/latest/main_classes/feature_attribution.html#inseq.attr.feat.ReagentAttribution) ReAGent: A Model-agnostic Feature Attribution Method for Generative Language Models. 

**<span style="color:grey">Zhixue Zhao</span>** and Boxuan Shan. 2024. 

[EMNLP 2022 Findings](https://aclanthology.org/2022.findings-emnlp.298/) On the Impact of Temporal Concept Drift on Model Explanations.
**<span style="color:grey">Zhixue Zhao</span>**, George Chrysostomou, Kalina Bontcheva, and Nikolaos Aletras


Online Social Networks and Media, 29, 100205. 2022. [Journal](https://www.sciencedirect.com/science/article/abs/pii/S246869642200009X) Utilizing Subjectivity Level to Mitigate Identity Term Bias in Toxic Comments Classification. 
**<span style="color:grey">Zhixue Zhao</span>**, Ziqi Zhang, and Frank Hopfgartner.  


[WWW 2021 Companion](https://dl.acm.org/doi/abs/10.1145/3442442.3452313#:~:text=Our%20results%20show%20that%2C%20Out,such%20as%20CNN%20and%20BiLSTM.) A Comparative Study of Using Pre-trained Language Models for Toxic Comment Classification.
**<span style="color:grey">Zhixue Zhao</span>**, Ziqi Zhang, and Frank Hopfgartner. 2021. 


[CICLing 2019](https://easychair.org/publications/preprint/XGmR) Detecting Toxic Content Online and the Effect of Training Data on Classification Performance. 
**<span style="color:grey">Zhixue Zhao</span>**, Ziqi Zhang, and Frank Hopfgartner. 2019. 
