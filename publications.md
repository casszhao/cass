---
layout: default
is_contact: true
---



## Publications

[ICML2025](https://openreview.net/pdf?id=uqpML2nbIz) Rulebreakers Challenge: Revealing a Blind Spot in Large Language Models’ Reasoning with Formal Logic.

Jason Chan, Robert Gaizauskas, **<span style="color:grey">Zhixue Zhao</span>**


[ICML2025](https://openreview.net/pdf?id=QLKBm1PaCU) Position: Editing Large Language Models Poses Serious Safety Risks. 

Paul Youssef, **<span style="color:grey">Zhixue Zhao</span>**, Daniel Braun, Jörg Schlötterer, Christin Seifert


[ICLR2025](https://openreview.net/pdf?id=ugyqNEOjoU) ScImage: How good are multimodal large language models at scientific text-to-image generation? 

Leixin Zhang, Yinjie Cheng, Weihe Zhai, Steffen Eger, Jonas Belouadi, Fahimeh Moafian, **<span style="color:grey">Zhixue Zhao</span>**. 

[TACL2025](https://arxiv.org/pdf/2408.14398) Investigating Language-Specific Calibration for Pruning Multilingual Large Language Models

Simon Kurz, Jian-Jia Chen, Lucie Flek, **<span style="color:grey">Zhixue Zhao</span>**

[ICWSM26](https://arxiv.org/abs/2505.18916) SCRum-9: Multilingual Stance Classification over Rumours on Social Media

Yue Li, Jake Vasilakes, **<span style="color:grey">Zhixue Zhao</span>**, Carolina Scarton


[AAAI26 Oral](https://arxiv.org/pdf/2505.12189) Mitigating Content Effects on Reasoning in Language Models through Fine-Grained Activation Steering

Marco Valentino, Geonhee Kim, Dhairya Dalal, **<span style="color:grey">Zhixue Zhao</span>**, Andre Freitas


[AAAI2026 Poster](https://aaai.org/conference/aaai/aaai-26/main-technical-track-call/) Making Visual Dialogue More Engaging: A New Task, Method, and Metric

Guanghui Ye, Huan Zhao, Yingxue Gao, **<span style="color:grey">Zhixue Zhao</span>**, Kehan Wang, Xupeng Zha, Zhihua Jiang


[EMNLP2025 Main](https://arxiv.org/pdf/2412.03400?) Minimal, Local, and Robust: Embedding-Only Edits for Implicit Bias in T2I Models

Feng He, Chao Zhang, **<span style="color:grey">Zhixue Zhao</span>**


[EMNLP2025 Main Oral Top15%](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=bwiMxxsAAAAJ&sortby=pubdate&citation_for_view=bwiMxxsAAAAJ:hqOjcs7Dif8C) Label Set Optimization via Activation Distribution Kurtosis for Zero-Shot Classification with Generative Models

Yue Li, **<span style="color:grey">Zhixue Zhao</span>**, Carolina Scarton


[EMNLP2025 Main](https://arxiv.org/pdf/2508.19089) It's All About In-Context Learning! Teaching Extremely Low-Resource Languages to LLMs

Yue Li, **<span style="color:grey">Zhixue Zhao</span>**, Carolina Scarton

	
[EMNLP2025 Findings](QP.pdf) Revisiting Pruning vs Quantization for Small Language Models

Zihan Zhou, Simon Kurz, **<span style="color:grey">Zhixue Zhao</span>**


[EMNLP2025 Main](https://arxiv.org/abs/2508.19827) Analysing Chain of Thought Dynamics: Active Guidance or Unfaithful Post-hoc Rationalisation?

Samuel Lewis-Lim, Xingwei Tan, **<span style="color:grey">Zhixue Zhao</span>**, Nikolaos Aletras


[ACL2025 Main](https://aclanthology.org/2025.acl-long.1063/). Knowledge Image Matters: Improving Knowledge-Based Visual Reasoning with Multi-Image Large Language Models

Guanghui Ye, Huan Zhao, **<span style="color:grey">Zhixue Zhao</span>**, Xupeng Zha, Yang Liu, Zhihua Jiang


[ACL2025 Findings](https://aclanthology.org/2025.findings-acl.96/) Explainable Hallucination through Natural Language Inference Mapping

Wei-Fan Chen, **<span style="color:grey">Zhixue Zhao</span>**, Akbar Karimi, Lucie Flek


[Knowledge-Based Systems 2025](https://www.sciencedirect.com/science/article/pii/S0950705125016739) AI-generated content in cross-domain applications: Research trends, challenges and propositions

Jianxin Li, Liang Qu, Taotao Cai, **<span style="color:grey">Zhixue Zhao</span>**, Nur Al Hasan Haldar, Aneesh Krishna, Xiangjie Kong, Flavio Romero Macau, Tanmoy Chakraborty, Aniket Deroy, Binshan Lin, Karen Blackmore, Nasimul Noman, Jingxian Cheng, Ningning Cui, Jianliang Xu


[IEEE Transactions on Computational Social Systems](https://ieeexplore.ieee.org/document/11080351) CCDE: A Compact and Competitive Dialogue Evaluation Framework via Knowledge Distillation of Large Language Models

Guanghui Ye; Huan Zhao; Bo Li; Haijiao Chen; **<span style="color:grey">Zhixue Zhao</span>**; Zhihua Jiang

[NAACL2025 Main](https://aclanthology.org/2025.naacl-long.630/) How to Make LLMs Forget: On Reversing In-Context Knowledge Edits

Paul Youssef, **<span style="color:grey">Zhixue Zhao</span>**, Jörg Schlötterer, Christin Seifert. 


[NAACL2025 Main Oral](https://aclanthology.org/2025.naacl-long.492/) Has this Fact been Edited? Detecting Knowledge Edits in Language Models?

Paul Youssef, **<span style="color:grey">Zhixue Zhao</span>**, Jörg Schlötterer, Christin Seifert. 


[ECIR2025](https://link.springer.com/chapter/10.1007/978-3-031-88714-7_30) Do LLMs Provide Consistent Answers to Health-Related Questions Across Languages? 
Ipek Baris Schlicht, **<span style="color:grey">Zhixue Zhao</span>**, Burcu Sayin, Lucie Flek, Paolo Rosso 


[TACL2024 Vol. 12](https://transacl.org/index.php/tacl/article/view/6271) Investigating Hallucinations in Pruned Large Language Models for Abstractive Summarization.  

George Chrysostomou, **<span style="color:grey">Zhixue Zhao</span>**, Miles Williams, Nikolaos Aletras. 


[NAACL 2024 Main](https://arxiv.org/pdf/2403.12809) (oral presentation) Comparing Explanation Faithfulness between Multilingual and Monolingual Fine-tuned Language Models. 

**<span style="color:grey">Zhixue Zhao</span>**, Nikolaos Aletras

[JAMIA Vol.7 4(2024)](https://doi.org/10.1093/jamiaopen/ooae139) The FAIR database: facilitating access to public health research literature. 

**<span style="color:grey">Zhixue Zhao</span>**, James Thomas, Gregory Kell, Claire Stansfield, Mark Clowes, Sergio Graziosi, Jeff Brunton, Iain James Marshall, Mark Stevenson. 


[ReLM@AAAI24](https://arxiv.org/pdf/2402.00794) Use ReAGent via [Inseq](https://inseq.org/en/latest/main_classes/feature_attribution.html#inseq.attr.feat.ReagentAttribution) ReAGent: A Model-agnostic Feature Attribution Method for Generative Language Models. 

**<span style="color:grey">Zhixue Zhao</span>**, Boxuan Shan. 2024. 


[ACL 2023 Main](https://aclanthology.org/2023.acl-long.261/)
[[Oral](https://us06web.zoom.us/rec/play/TisLvdRrfqNRYts4y0A6wJeoV2H6kL2eRywX7Jl_wGUxBVO_n_HoIfVi1lhO0OK1sUw-gDjFpHuuDz6o.-zDGXXlaq7nOwrW7?canPlayFromShare=true&from=share_recording_detail&continueMode=true&componentName=rec-play&originRequestUrl=https%3A%2F%2Fus06web.zoom.us%2Frec%2Fshare%2Fc0BepePE3QACrdQQpFnEISDmrUSvV5T7XwJcW1TN0jkGEvVMutm55KeLx9eKWXH4.R0SYaV552qVO0sfV) (the 1st talk was ours)] Incorporating Attribution Importance for Improving Faithfulness Metrics.

**<span style="color:grey">Zhixue Zhao</span>**, Nikolaos Aletras


[EMNLP 2022 Findings](https://aclanthology.org/2022.findings-emnlp.298/) On the Impact of Temporal Concept Drift on Model Explanations. 

**<span style="color:grey">Zhixue Zhao</span>**, George Chrysostomou, Kalina Bontcheva, Nikolaos Aletras.


[Online Social Networks and Media 2022](https://www.sciencedirect.com/science/article/abs/pii/S246869642200009X) Utilizing Subjectivity Level to Mitigate Identity Term Bias in Toxic Comments Classification. 

**<span style="color:grey">Zhixue Zhao</span>**, Ziqi Zhang, Frank Hopfgartner.  


[WWW 2021 Companion](https://dl.acm.org/doi/abs/10.1145/3442442.3452313#:~:text=Our%20results%20show%20that%2C%20Out,such%20as%20CNN%20and%20BiLSTM.) A Comparative Study of Using Pre-trained Language Models for Toxic Comment Classification.

**<span style="color:grey">Zhixue Zhao</span>**, Ziqi Zhang, Frank Hopfgartner. 2021. 


[CICLing 2019](https://easychair.org/publications/preprint/XGmR) Detecting Toxic Content Online and the Effect of Training Data on Classification Performance. 

**<span style="color:grey">Zhixue Zhao</span>**, Ziqi Zhang, Frank Hopfgartner. 2019. 
